summary(c1$contrasts) %>% pander
summary(c2$contrasts) %>% pander
# Read Data
dat <- read_csv('study1_sorted.csv')
dat$SubID <- as.factor(dat$SubID)
wordList <- read_excel('study1_stimuli.xlsx',2)
combined <- left_join(dat, wordList, by = c("ListID","TrialID"))
combined$SubID <- as.factor(combined$SubID)
combined <- combined %>% filter(Condition=="Interpret") %>% filter(cue_valid_med >= 3)
temp <- combined %>%
filter(TrialType == "Main") %>%
filter(ldt_word_type == "target")
# Read Data
dat <- read_csv('study1_sorted.csv')
dat$SubID <- as.factor(dat$SubID)
wordList <- read_excel('study1_stimuli.xlsx',2)
combined <- left_join(dat, wordList, by = c("ListID","TrialID"))
combined$SubID <- as.factor(combined$SubID)
combined <- combined %>% filter(Condition=="Interpret") %>% filter(cue_valid_med >= 3)
dat <- read_csv('study1_sorted.csv')
dat$SubID <- as.factor(dat$SubID)
wordList <- read_excel('study1_stimuli.xlsx',2)
combined <- left_join(dat, wordList, by = c("ListID","TrialID"))
combined$SubID <- as.factor(combined$SubID)
combined <- combined %>% filter(Condition=="Interpret")
14200/200
temp <- combined %>%
filter(TrialType == "Main") %>%
filter(ldt_word_type == "target") %>%
filter(Sense == 2) %>%
filter(LDT == 2) %>%
filter(LDTRT > 0.2 & LDTRT < 1.5)
print("excluded percentage is ")
(3501 - 2385)/3501*100
(3501 - 2385)
temp <- temp %>% group_by(SubID, cue) %>%
mutate(count = n())
temp <- temp %>% group_by(SubID) %>%
mutate(total = n()) %>%
mutate(ratio = count/total) %>%
filter(ratio != 0 & ratio != 1)
age <- temp %>% group_by(SubID, Gender) %>%
summarise(ave_age = mean(Age))
c(mean(age$ave_age), sd(age$ave_age), max(age$ave_age), min(age$ave_age)) %>% round(2)
age %>% group_by(Gender) %>% summarise(n())
m1 <- lmer(LDTRT ~ InterType*cue  + (1|SubID), data=temp)
coef(summary(m1)) %>% pander
c1 <- lsmeans(m1, pairwise~cue|InterType, adjust="tukey")
c2 <- lsmeans(m1, pairwise~InterType|cue, adjust="tukey")
summary(c1$contrasts) %>% pander
summary(c2$contrasts) %>% pander
ggbarplot(temp, x="InterType", y="LDTRT", color="cue", add= c("mean_se"), label=TRUE, label.pos="out", lab.nb.digits=2, position = position_dodge(0.8))
# Read Data
dat <- read_csv('study1_sorted.csv')
dat$SubID <- as.factor(dat$SubID)
wordList <- read_excel('study1_stimuli.xlsx',2)
combined <- left_join(dat, wordList, by = c("ListID","TrialID"))
combined$SubID <- as.factor(combined$SubID)
combined <- combined %>% filter(Condition=="Interpret") %>% filter(cue_valid_med >= 3)
temp <- combined %>%
filter(TrialType == "Main") %>%
filter(ldt_word_type == "target") %>%
filter(Sense == 2) %>%
filter(LDT == 2) %>%
filter(LDTRT > 0.2 & LDTRT < 1.5)
print("excluded percentage is ")
(3501 - 2385)/3501*100
(3501 - 2385)
temp <- temp %>% group_by(SubID, cue) %>%
mutate(count = n())
temp <- temp %>% group_by(SubID) %>%
mutate(total = n()) %>%
mutate(ratio = count/total) %>%
filter(ratio != 0 & ratio != 1)
# Read Data
dat <- read_csv('study1_sorted.csv')
dat$SubID <- as.factor(dat$SubID)
wordList <- read_excel('study1_stimuli.xlsx',2)
combined <- left_join(dat, wordList, by = c("ListID","TrialID"))
combined$SubID <- as.factor(combined$SubID)
combined <- combined %>% filter(Condition=="Interpret") %>% filter(cue_valid_med >= 3)
temp <- combined %>%
filter(TrialType == "Main") %>%
filter(ldt_word_type == "target")
temp <- combined %>%
filter(TrialType == "Main") %>%
filter(ldt_word_type == "target") %>%
filter(Sense == 2) %>%
filter(LDT == 2) %>%
filter(LDTRT > 0.2 & LDTRT < 1.5)
temp <- temp %>% group_by(SubID, cue) %>%
mutate(count = n())
temp <- temp %>% group_by(SubID) %>%
mutate(total = n()) %>%
mutate(ratio = count/total) %>%
filter(ratio != 0 & ratio != 1)
temp <- combined %>%
filter(TrialType == "Main") %>%
filter(ldt_word_type == "target")
4000/200
combined <- combined %>% filter(Condition=="Interpret") %>% filter(cue_valid_med >= 3)
# Read Data
dat <- read_csv('study1_sorted.csv')
dat$SubID <- as.factor(dat$SubID)
wordList <- read_excel('study1_stimuli.xlsx',2)
combined <- left_join(dat, wordList, by = c("ListID","TrialID"))
combined$SubID <- as.factor(combined$SubID)
combined <- combined %>% filter(Condition=="Interpret") %>% filter(cue_valid_med >= 3)
View(combined)
hist(combined$cue_valid_mean)
summary(combined$cue_valid_mean)
sum(combined$cue_valid_mean <= 3)
sum(combined$cue_valid_mean <= 3)/200
dat <- read_csv('study1_sorted.csv')
dat$SubID <- as.factor(dat$SubID)
wordList <- read_excel('study1_stimuli.xlsx',2)
combined <- left_join(dat, wordList, by = c("ListID","TrialID"))
combined$SubID <- as.factor(combined$SubID)
combined <- combined %>% filter(Condition=="Interpret")
dat <- read_csv('study1_sorted.csv')
dat$SubID <- as.factor(dat$SubID)
wordList <- read_excel('study1_stimuli.xlsx',2)
combined <- left_join(dat, wordList, by = c("ListID","TrialID"))
combined$SubID <- as.factor(combined$SubID)
combined <- combined %>%
filter(Condition=="Interpret") %>%
filter(TrialType == "Main") %>%
filter(ldt_word_type == "target")
temp <- combined %>%
filter(Sense == 2) %>%
filter(LDT == 2) %>%
filter(LDTRT > 0.2 & LDTRT < 1.5)
temp <- combined %>%
filter(Sense == 2) %>%
filter(LDT == 2) %>%
filter(LDTRT > 0.2 & LDTRT < 1.5)
print("excluded percentage is ")
(3501 - 2385)/3501*100
(3501 - 2385)
temp <- temp %>% group_by(SubID, cue) %>%
mutate(count = n())
temp <- temp %>% group_by(SubID) %>%
mutate(total = n()) %>%
mutate(ratio = count/total) %>%
filter(ratio != 0 & ratio != 1)
# Read Data
dat <- read_csv('study1_sorted.csv')
dat$SubID <- as.factor(dat$SubID)
wordList <- read_excel('study1_stimuli.xlsx',2)
combined <- left_join(dat, wordList, by = c("ListID","TrialID"))
combined$SubID <- as.factor(combined$SubID)
combined <- combined %>%
filter(Condition=="Interpret") %>%
filter(TrialType == "Main") %>%
filter(ldt_word_type == "target") %>%
filter(cue_valid_med >= 3)
dat <- read_csv('study1_sorted.csv')
dat$SubID <- as.factor(dat$SubID)
wordList <- read_excel('study1_stimuli.xlsx',2)
combined <- left_join(dat, wordList, by = c("ListID","TrialID"))
combined$SubID <- as.factor(combined$SubID)
combined <- combined %>%
filter(Condition=="Interpret") %>%
filter(TrialType == "Main") %>%
filter(ldt_word_type == "target")
combined <- combined %>%
filter(Condition=="Interpret") %>%
filter(TrialType == "Main") %>%
filter(ldt_word_type == "target") %>%
filter(cue_valid_med > 3)
# Read Data
dat <- read_csv('study1_sorted.csv')
dat$SubID <- as.factor(dat$SubID)
wordList <- read_excel('study1_stimuli.xlsx',2)
combined <- left_join(dat, wordList, by = c("ListID","TrialID"))
combined$SubID <- as.factor(combined$SubID)
combined <- combined %>%
filter(Condition=="Interpret") %>%
filter(TrialType == "Main") %>%
filter(ldt_word_type == "target") %>%
filter(cue_valid_med >= 3)
temp <- combined %>%
filter(Sense == 2) %>%
filter(LDT == 2) %>%
filter(LDTRT > 0.2 & LDTRT < 1.5)
print("excluded percentage is ")
(3501 - 2385)/3501*100
(3501 - 2385)
temp <- temp %>% group_by(SubID, cue) %>%
mutate(count = n())
temp <- temp %>% group_by(SubID) %>%
mutate(total = n()) %>%
mutate(ratio = count/total) %>%
filter(ratio != 0 & ratio != 1)
m1 <- lmer(LDTRT ~ InterType*cue  + (1|SubID), data=temp)
coef(summary(m1)) %>% pander
c1 <- lsmeans(m1, pairwise~cue|InterType, adjust="tukey")
c2 <- lsmeans(m1, pairwise~InterType|cue, adjust="tukey")
summary(c1$contrasts) %>% pander
summary(c2$contrasts) %>% pander
# Read Data
dat <- read_csv('study1_sorted.csv')
dat$SubID <- as.factor(dat$SubID)
wordList <- read_excel('study1_stimuli.xlsx',2)
combined <- left_join(dat, wordList, by = c("ListID","TrialID"))
combined$SubID <- as.factor(combined$SubID)
combined <- combined %>%
filter(Condition=="Interpret") %>%
filter(TrialType == "Main") %>%
filter(ldt_word_type == "target") %>%
filter(cue_valid_med > 3)
temp <- combined %>%
filter(Sense == 2) %>%
filter(LDT == 2) %>%
filter(LDTRT > 0.2 & LDTRT < 1.5)
print("excluded percentage is ")
(3501 - 2385)/3501*100
(3501 - 2385)
temp <- temp %>% group_by(SubID, cue) %>%
mutate(count = n())
temp <- temp %>% group_by(SubID) %>%
mutate(total = n()) %>%
mutate(ratio = count/total) %>%
filter(ratio != 0 & ratio != 1)
age <- temp %>% group_by(SubID, Gender) %>%
summarise(ave_age = mean(Age))
c(mean(age$ave_age), sd(age$ave_age), max(age$ave_age), min(age$ave_age)) %>% round(2)
age %>% group_by(Gender) %>% summarise(n())
m1 <- lmer(LDTRT ~ InterType*cue  + (1|SubID), data=temp)
coef(summary(m1)) %>% pander
c1 <- lsmeans(m1, pairwise~cue|InterType, adjust="tukey")
c2 <- lsmeans(m1, pairwise~InterType|cue, adjust="tukey")
summary(c1$contrasts) %>% pander
summary(c2$contrasts) %>% pander
length(combined[,1])
length(t(combined[,1]))
length(t(combined[,1])) - length(t(temp[,1]))
(length(t(combined[,1])) - length(t(temp[,1])))/length(t(combined[,1]))
age <- temp %>% group_by(SubID, Gender) %>%
summarise(ave_age = mean(Age))
c(mean(age$ave_age), sd(age$ave_age), max(age$ave_age), min(age$ave_age)) %>% round(2)
age %>% group_by(Gender) %>% summarise(n())
m1 <- lmer(LDTRT ~ InterType*cue  + (1|SubID), data=temp)
coef(summary(m1)) %>% pander
c1 <- lsmeans(m1, pairwise~cue|InterType, adjust="tukey")
c2 <- lsmeans(m1, pairwise~InterType|cue, adjust="tukey")
summary(c1$contrasts) %>% pander
summary(c2$contrasts) %>% pander
store.df <- read.csv("http://goo.gl/QPDdMl")
View(store.df)
set.seed(21282)
cust.df <- data.frame(cust.id = as.factor(c(1:ncust)))
ncust <- 1000
cust.df <- data.frame(cust.id = as.factor(c(1:ncust)))
View(cust.df)
cust.df$age <- rnorm(n=ncust, mean=35, sd=5)
View(cust.df)
View(store.df)
install.packages("itsadug")
library(itsadug)
data(simdat)
force(simdat)
View(simdat)
acf_n_plots(simdat$Y, split_by=list(simdat$Subject, simdat$Trial))
acf_n_plots(simdat$Y, split_by=list(simdat$Subject))
rm(list=ls())
install.packages("pupilometryR")
install.packages("pupillometryR")
install.packages("PupillometryR")
library(PupillometryR)
data("pupil_data")
head(pupil_data)
View(pupil_data)
Sdata <- make_pupillometryr_data(data = pupil_data,
subject = ID,
trial = Trial,
time = Time,
condition = Type)
View(Sdata)
View(pupil_data)
View(Sdata)
View(pupil_data)
View(Sdata)
new_data <- replace_missing_data(data = Sdata)
View(Sdata)
plot(new_data, pupil = LPupil, group = 'condition')
plot(new_data, pupil = LPupil, group = 'subject')
regressed_data <- regress_data(data = new_data,
pupil1 = RPupil,
pupil2 = LPupil)
mean_data <- calculate_mean_pupil_size(data = regressed_data,
pupil1 = RPupil,
pupil2 = LPupil)
filtered_data <- filter_data(data = mean_data,
pupil = mean_pupil,
filter = 'median',
degree = 11)
rm(list=ls())
set.seed(42)
library("Matrix")
library("lme4")
library("ggplot2")
library("eyetrackingR")
data("word_recognition")
data <- make_eyetrackingr_data(word_recognition,
participant_column = "ParticipantName",
trial_column = "Trial",
time_column = "TimeFromTrialOnset",
trackloss_column = "TrackLoss",
aoi_columns = c('Animate','Inanimate'),
treat_non_aoi_looks_as_missing = TRUE
)
install.packages("eyetrackingR")
set.seed(42)
library("Matrix")
library("lme4")
library("ggplot2")
library("eyetrackingR")
data("word_recognition")
data <- make_eyetrackingr_data(word_recognition,
participant_column = "ParticipantName",
trial_column = "Trial",
time_column = "TimeFromTrialOnset",
trackloss_column = "TrackLoss",
aoi_columns = c('Animate','Inanimate'),
treat_non_aoi_looks_as_missing = TRUE
)
View(data)
remotes::install_github("dmirman/gazer")
dat.mod <- dat.mod %>% mutate(cond = ifelse(con1=="5min", 1, 0))
Packages <- c("readxl", "readr", "lme4", "tidyverse","ggplot2","jmv","lmerTest","epiDisplay","kableExtra","ggpubr","medmod","pander","margins","probemod","reshape2","interactions","lavaan","corrplot","sjPlot","lsmeans")
lapply(Packages, library, character.only = TRUE)
setwd("~/Dropbox/SangSuk R/scent/study5")
dat.mod <- read_csv("study5_spotlight.csv")
dat <- read_xlsx("study5_coded.xlsx", na="NaN")
dat <- dat %>% filter(con1 != "1min")
dat.like.long <- gather(dat, type, like, l_fries, l_cice, l_fruit, l_cbar, na.rm=TRUE)
dat.like.long <- dat.like.long %>%
mutate(indulge = ifelse(type == "l_fries" | type == "l_cice", 1, 0),
relevant = ifelse(type == "l_cice" | type == "l_cbar", 1, 0))
dat.purchase.long <- gather(dat, type, purchase, p_fries, p_cice, p_fruit, p_cbar, na.rm=TRUE)
dat.purchase.long <- dat.purchase.long %>%
mutate(indulge = ifelse(type == "p_fries" | type == "p_cice", 1, 0),
relevant = ifelse(type == "p_cice" | type == "p_cbar", 1, 0))
dat.index.long <- gather(dat, type, index, fries_index, ice_index, fruit_index, bar_index, na.rm=TRUE)
dat.index.long <- dat.index.long %>%
mutate(indulge = ifelse(type == "fries_index" | type == "ice_index", 1, 0),
relevant = ifelse(type == "ice_index" | type == "bar_index", 1, 0))
dat.mod <- dat.mod %>% mutate(cond = ifelse(con1=="5min", 1, 0))
mod.reg <- lm(index_like ~ cond*res, data=dat.mod)
summary(mod.reg)
sim_slopes(mod.reg, pred = cond, modx = res, jnplot = TRUE)
interact_plot(mod.reg, pred = cond, modx = res, interval = TRUE)
interact_plot(mod.reg, pred = res, modx = cond, interval = TRUE)
medmod::mod(
data = dat.mod,
dep = "index_like",
mod = "res",
pred = "cond",
estMethod = "bootstrap",
bootstrap = 5000,
ci = TRUE,
simpleSlopeEst = TRUE,
simpleSlopePlot = TRUE)
papresults <- pickapoint(mod.reg, dv='index_like', iv='cond', mod='res')
plot(papresults)
jn(mod.reg, dv='index_like', iv='cond', mod='res')
library(Statamarkdown)
library(devtools) # before this you may need to install devtools
install_github("hemken/Statamarkdown")
library(Statamarkdown)
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
setwd('~/Dropbox/Research/choice reversal/study17/Online_Spring2020/')
# Read required packages
Packages <- c("readxl", "readr", "lme4", "dplyr","ggplot2","jmv","reshape2","tidyverse","ggpubr","lmerTest","interactions","sjPlot","emmeans","lsmeans","pander","sjPlot","interactions","emmeans")
lapply(Packages, library, character.only = TRUE)
# Read Data
p1.data <- read_csv('Phase1_Data.csv')
p2.data <- read_csv('Phase2_Data.csv')
wtp.data <- read_csv('WTP_Data.csv')
p2.data$SubID <- as.factor(p2.data$SubID)
p2.data <- p2.data %>%
mutate(Conditions = case_when(
Cond1 == "Choose" & Cond2 == "Choose" ~ "CC",
Cond1 == "Choose" & Cond2 == "Reject" ~ "CR",
Cond1 == "Reject" & Cond2 == "Choose" ~ "RC",
Cond1 == "Reject" & Cond2 == "Reject" ~ "RR"),
target = ifelse(Options == Preferred1, 1, 0),
ItemCat = ifelse(CatID==1,"Coffee","Lights"))
col_names <- c("Cond1","Cond2","CatID")
p2.data[ , col_names] <- lapply(p2.data[ , col_names] , factor)
# Exclude based on 3RT
p2.data <- p2.data %>%
mutate(lnRT1 = log(RT1),
lnRT2 = log(RT2)) %>%
group_by(CatID) %>%
filter(RT1 > (mean(RT1) - 3*sd(RT1)) & RT1 < (mean(RT1) + 3*sd(RT1))) %>%
filter(RT2 > (mean(RT2) - 3*sd(RT2)) & RT2 < (mean(RT2) + 3*sd(RT2)))
p2.data <- p2.data %>%  group_by(SubID) %>%
mutate(count = n()) %>%
filter(count == 4)
library(patchwork)
install.packages("patchwork")
ggscater(p2.data[p2.data$target==1 & p2.data$Cond1=="Choose" & p2.data$Cond2=="Choose",], "RT1", "Preferred")
ggscatter(p2.data[p2.data$target==1 & p2.data$Cond1=="Choose" & p2.data$Cond2=="Choose",], "RT1", "Preferred")
cc <- lmer(Preferred ~ RT1 + (1|SubID), data=p2.data[p2.data$target==1 & p2.data$Cond1=="Choose" & p2.data$Cond2=="Choose",])
cr <- lmer(Preferred ~ RT1 + (1|SubID), data=p2.data[p2.data$target==1 & p2.data$Cond1=="Choose" & p2.data$Cond2=="Reject",])
rc <- lmer(Preferred ~ RT1 + (1|SubID), data=p2.data[p2.data$target==1 & p2.data$Cond1=="Reject" & p2.data$Cond2=="Choose",])
rr <- lmer(Preferred ~ RT1 + (1|SubID), data=p2.data[p2.data$target==1 & p2.data$Cond1=="Reject" & p2.data$Cond2=="Reject",])
tab_model(cc,cr,rc,rr, show.ci=FALSE, dv.labels=c("CC","CR","RC","RR"))
cc <- glmer(Preferred ~ RT1 + (1|SubID), data=p2.data[p2.data$target==1 & p2.data$Cond1=="Choose" & p2.data$Cond2=="Choose",], family=binomial(link="logit"))
cr <- glmer(Preferred ~ RT1 + (1|SubID), data=p2.data[p2.data$target==1 & p2.data$Cond1=="Choose" & p2.data$Cond2=="Reject",], family=binomial(link="logit"))
rc <- glmer(Preferred ~ RT1 + (1|SubID), data=p2.data[p2.data$target==1 & p2.data$Cond1=="Reject" & p2.data$Cond2=="Choose",], family=binomial(link="logit"))
rr <- glmer(Preferred ~ RT1 + (1|SubID), data=p2.data[p2.data$target==1 & p2.data$Cond1=="Reject" & p2.data$Cond2=="Reject",], family=binomial(link="logit"))
tab_model(cc,cr,rc,rr, show.ci=FALSE, dv.labels=c("CC","CR","RC","RR"))
View(p2.data)
lmer(RT2 ~ Conditions + (1|SubID), data=p2.data[p2.data$Options=="A",])
summary(lmer(RT2 ~ Conditions + (1|SubID), data=p2.data[p2.data$Options=="A",]))
summary(rt2.aov <- lmer(RT2 ~ Conditions + (1|SubID), data=p2.data[p2.data$Options=="A",]))
anova(rt2.aov)
rt2.aov <- lmer(RT2 ~ Conditions + (1|SubID), data=p2.data[p2.data$Options=="A",])
anova(rt2.aov)
lsmeans(rt2.aov, pairwise ~ Conditions, adjust="tukey")
rt2.aov <- lmer(RT2 ~ Cond1*Cond2 + (1|SubID), data=p2.data[p2.data$Options=="A",])
anova(rt2.aov)
ct1 <- lsmeans(rt2.aov, pairwise ~ Cond1|Cond2, adjust="tukey")
rt2.aov <- lmer(RT2 ~ Cond1*Cond2 + (1|SubID), data=p2.data[p2.data$Options=="A",])
anova(rt2.aov)
ct1 <- lsmeans(rt2.aov, pairwise ~ Cond1|Cond2, adjust="tukey")
ct1$contrasts %>% pander
ct1 <- lsmeans(rt2.aov, pairwise ~ Cond1|Cond2, adjust="tukey")
ct1$contrasts %>% pander
ct1
ct1$contrasts
ct1$contrasts %>% pander
rt2.aov <- lmer(RT2 ~ Cond1*Cond2 + (1|SubID), data=p2.data[p2.data$Options=="A",])
anova(rt2.aov)
ct1 <- lsmeans(rt2.aov, pairwise ~ Cond1|Cond2, adjust="tukey")
ct1$contrasts
rt2.aov <- lmer(RT2 ~ Cond1*Cond2 + (1|SubID), data=p2.data[p2.data$Options=="A",])
anova(rt2.aov)
ct1 <- lsmeans(rt2.aov, pairwise ~ Cond1|Cond2, adjust="tukey")
ct1$contrasts
ct2 <- lsmeans(rt2.aov, pairwise ~ Cond2|Cond1, adjust="tukey")
ct2$contrasts
rt2.dat <- rt2.dat %>% mutate(congruent = ifelse(Cond1==Cond2, 1, 0))
rt2.dat <- p2.data[p2.data$Options=="A",]
rt2.dat <- rt2.dat %>% mutate(congruent = ifelse(Cond1==Cond2, 1, 0))
rt2.aov <- lmer(RT2 ~ congruent + (1|SubID), data=rt2.dat)
anova(rt2.aov)
rt2.dat <- p2.data[p2.data$Options=="A",]
rt2.dat <- rt2.dat %>% mutate(congruent = ifelse(Cond1==Cond2, 1, 0))
rt2.aov <- lmer(RT2 ~ congruent + (1|SubID), data=rt2.dat)
anova(rt2.aov)
ct1 <- lsmeans(rt2.aov, pairwise ~ congruent, adjust="tukey")
ct1$contrasts
rt2.aov <- lmer(RT2 ~ Conditions + (1|SubID), data=p2.data[p2.data$Options=="A",])
anova(rt2.aov)
lsmeans(rt2.aov, pairwise ~ Conditions, adjust="tukey")
ggbarplort(p2.data[p2.data$Options=="A",], "Conditions", "RT2")
?ggbarplot
ggbarplot(p2.data[p2.data$Options=="A",], "Conditions", "RT2")
ggbarplot(p2.data[p2.data$Options=="A",], "Conditions", "RT2", add="mean_sd")
ggbarplot(p2.data[p2.data$Options=="A",], "Conditions", "RT2", add="mean_sd", label=TRUE)
ggbarplot(p2.data[p2.data$Options=="A",], "Conditions", "RT2", add="mean_sd", label=TRUE, label.nb.digits=2)
ggbarplot(p2.data[p2.data$Options=="A",], "Conditions", "RT2", add="mean_sd", label=TRUE, lab.nb.digits=2)
rt2.aov <- lmer(RT2 ~ Conditions + (1|SubID), data=p2.data[p2.data$Options=="A",])
anova(rt2.aov)
ct1 <- lsmeans(rt2.aov, pairwise ~ Conditions, adjust="tukey")
ct1$contrasts
ggbarplot(p2.data[p2.data$Options=="A",], "Conditions", "RT2", add="mean_sd", label=TRUE, lab.nb.digits=2)
ggbarplot(rt2.dat, "congruent", "RT2", add="mean_sd")
ggbarplot(rt2.dat, "congruent", "RT2", add="mean_sd", label=TRUE, lab.nb.digits=2)
rt2.dat <- p2.data[p2.data$Options=="A",]
rt2.dat <- rt2.dat %>% mutate(congruent = ifelse(Cond1==Cond2, 1, 0))
rt2.aov <- lmer(RT2 ~ congruent + (1|SubID), data=rt2.dat)
anova(rt2.aov)
ct1 <- lsmeans(rt2.aov, pairwise ~ congruent, adjust="tukey")
ct1$contrasts
ggbarplot(rt2.dat, "congruent", "RT2", add="mean_sd", label=TRUE, lab.nb.digits=2)
rt2.aov <- lmer(RT2 ~ Cond1*Cond2 + (1|SubID), data=p2.data[p2.data$Options=="A",])
anova(rt2.aov)
ct1 <- lsmeans(rt2.aov, pairwise ~ Cond1|Cond2, adjust="tukey")
ct1$contrasts
ct2 <- lsmeans(rt2.aov, pairwise ~ Cond2|Cond1, adjust="tukey")
ct2$contrasts
setwd("/users/sangsuk/Documents/website/ssyoon.github.io")
rmarkdown::render_site()
rmarkdown::render_site()
rmarkdown::render_site()
I am an Assistant Professor at University of Dayton. I'm studying cognitive biases underlying human decision making, and seek to apply findings from laboratory studies in judgment and decision making to real-life consumer preferences (e.g., consumer preference, financial decision making, advertisement, and risk communications). I am also interested in using a multi-methodological approach, including behavioral, computational modeling, eye-tracking and fMRI, to obtain converging evidence about the underlying mechanisms of decision biases.
setwd("/users/sangsuk/Documents/website/ssyoon.github.io")
rmarkdown::render_site()
setwd("/users/sangsuk/Documents/website/ssyoon.github.io")
rmarkdown::render_site()
blogdown::new_site(theme = "lxndrblz/anatole")
install.packages("blogdown")
library(blogdown)
blogdown::new_site(theme = "lxndrblz/anatole")
rmarkdown::render_site()
setwd("/users/sangsuk/Documents/personal_website/ssyoon.github.io")
rmarkdown::render_site()
setwd("/users/sangsuk/Documents/personal_website/ssyoon.github.io")
rmarkdown::render_site()
setwd("/users/sangsuk/Documents/personal_website/ssyoon.github.io")
rmarkdown::render_site()
setwd("/users/sangsuk/Documents/personal_website/ssyoon.github.io")
rmarkdown::render_site()
setwd("/users/sangsuk/Documents/personal_website/ssyoon.github.io")
rmarkdown::render_site()
setwd("/users/sangsuk/Documents/personal_website/ssyoon.github.io")
rmarkdown::render_site()
